"ï»¿Column1.2","Column2","Column6","Column7","Column8","Column9","Column10","Column11","Column12","Column13","Column14","Column15","Column16","Column17","Column18","Column19"
"[EXT] [RSS] Feed from Cornwell","CAUTION: This email originated from outside of our organization. Unless you recognize the sender and know that the content is safe, do not click on links or open attachments. For questions please contact Group CSIRT	 


TITLE[|Object-Centric Local Process Models <https://urldefense.com/v3/__https://arxiv.org/abs/2411.10468__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitb61nCrA$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2411.10468v1 Announce Type: new Abstract: Process mining is a technology that helps understand, analyze, and improve processes. It has been present for around two decades, and although initially tailored for business processes, the spectrum of analyzed processes nowadays is evermore growing. To support more complex and diverse processes, subdisciplines such as object-centric process mining and behavioral pattern mining have emerged. Behavioral patterns allow for analyzing parts of the process in isolation, while object-centric process mining enables combining different perspectives of the process. In this work, we introduce \emph{Object-Centric Local Process Models} (OCLPMs). OCLPMs are behavioral patterns tailored to analyzing complex processes where no single case notion exists and we leverage object-centric Petri nets to model them. Additionally, we present a discovery algorithm that starts from object-centric event logs, and implement the proposed approach in the open-source framework ProM. Finally, we demonstrate the applicability of OCLPMs in two case studies and evaluate the approach on various event logs.|] 

TITLE[|KV-Tandem -- a Modular Approach to Building High-Speed LSM Storage Engines <https://urldefense.com/v3/__https://arxiv.org/abs/2411.11091__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitwgb4wFQ$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2411.11091v1 Announce Type: new Abstract: We present~\emph{KV-Tandem}, a modular architecture for building LSM-based storage engines on top of simple, non-ordered persistent key-value stores (KVSs). KV-Tandem enables advanced functionalities such as range queries and snapshot reads, while maintaining the native KVS performance for random reads and writes. Its modular design offers better performance trade-offs compared to previous KV-separation solutions, which struggle to decompose the monolithic LSM structure. Central to KV-Tandem is~\emph{LSM bypass} -- a novel algorithm that offers a fast path to basic operations while ensuring the correctness of advanced APIs. We implement KV-Tandem in \emph{XDP-Rocks}, a RocksDB-compatible storage engine that leverages the XDP KVS and incorporates practical design optimizations for real-world deployment. Through extensive microbenchmark and system-level comparisons, we demonstrate that XDP-Rocks achieves 3x to 4x performance improvements over RocksDB across various workloads. XDP-Rocks is already deployed in production, delivering significant operator cost savings consistent with these performance gains.|] 

TITLE[|Lorentz: Learned SKU Recommendation Using Profile Data <https://urldefense.com/v3/__https://arxiv.org/abs/2411.11325__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitbpYtRAU$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2411.11325v1 Announce Type: new Abstract: Cloud operators have expanded their service offerings, known as Stock Keeping Units (SKUs), to accommodate diverse demands, resulting in increased complexity for customers to select appropriate configurations. In a studied system, only 43% of the resource capacity was correctly chosen. Automated solutions addressing this issue often require enriched data, such as workload traces, which are unavailable for new services. However, telemetry from existing users and customer satisfaction feedback provide valuable insights for understanding customer needs and improving provisioning recommendations. This paper introduces Lorentz, an intelligent SKU recommender for provisioning compute resources without relying on workload traces. Lorentz uses customer profile data to forecast resource capacities for new users by profiling existing ones. It also incorporates a continuous feedback loop to refine recommendations based on customer performance versus cost preferences inferred from satisfaction signals. Validated with production data from Azure PostgreSQL DB, Lorentz achieves over 60% slack reduction without increasing throttling compared to user selections and existing defaults. Evaluations with synthetic data demonstrate Lorentz's ability to iteratively learn user preferences with high accuracy.|] 

TITLE[|Intelligent Pooling: Proactive Resource Provisioning in Large-scale Cloud Service <https://urldefense.com/v3/__https://arxiv.org/abs/2411.11326__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitykaxxxg$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2411.11326v1 Announce Type: new Abstract: The proliferation of big data and analytic workloads has driven the need for cloud compute and cluster-based job processing. With Apache Spark, users can process terabytes of data at ease with hundreds of parallel executors. At Microsoft, we aim at providing a fast and succinct interface for users to run Spark applications, such as through creating simple notebook ""sessions"" by abstracting the underlying complexity of the cloud. Providing low latency access to Spark clusters and sessions is a challenging problem due to the large overheads of cluster creation and session startup. In this paper, we introduce Intelligent Pooling, a system for proactively provisioning compute resources to combat the aforementioned overheads. To reduce the COGS (cost-of-goods-sold), our system (1) predicts usage patterns using an innovative hybrid Machine Learning (ML) model with low latency and high accuracy; and (2) optimizes the pool size dynamically to meet customer demand while reducing extraneous COGS. The proposed system auto-tunes its hyper-parameters to balance between performance and operational cost with minimal to no engineering input. Evaluated using large-scale production data, Intelligent Pooling achieves up to 43% reduction in cluster idle time compared to static pooling when targeting 99% pool hit rate. Currently deployed in production, Intelligent Pooling is on track to save tens of million dollars in COGS per year as compared to traditional pre-provisioned pools.|] 

TITLE[|Graph Neural Networks on Graph Databases <https://urldefense.com/v3/__https://arxiv.org/abs/2411.11375__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitA8k5s3A$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2411.11375v1 Announce Type: cross Abstract: Training graph neural networks on large datasets has long been a challenge. Traditional approaches include efficiently representing the whole graph in-memory, designing parameter efficient and sampling-based models, and graph partitioning in a distributed setup. Separately, graph databases with native graph storage and query engines have been developed, which enable time and resource efficient graph analytics workloads. We show how to directly train a GNN on a graph DB, by retrieving minimal data into memory and sampling using the query engine. Our experiments show resource advantages for single-machine and distributed training. Our approach opens up a new way of scaling GNNs as well as a new application area for graph DBs.|] 

TITLE[|Towards Scalable and Practical Batch-Dynamic Connectivity <https://urldefense.com/v3/__https://arxiv.org/abs/2411.11781__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitOfqwa5g$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2411.11781v1 Announce Type: cross Abstract: We study the problem of dynamically maintaining the connected components of an undirected graph subject to edge insertions and deletions. We give the first parallel algorithm for the problem which is work-efficient, supports batches of updates, runs in polylogarithmic depth, and uses only linear total space. The existing algorithms for the problem either use super-linear space, do not come with strong theoretical bounds, or are not parallel. On the empirical side, we provide the first implementation of the cluster forest algorithm, the first linear-space and poly-logarithmic update time algorithm for dynamic connectivity. Experimentally, we find that our algorithm uses up to 19.7x less space and is up to 6.2x faster than the level-set algorithm of HDT, arguably the most widely-implemented dynamic connectivity algorithm with strong theoretical guarantees.|] 

TITLE[|Tackling prediction tasks in relational databases with LLMs <https://urldefense.com/v3/__https://arxiv.org/abs/2411.11829__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitCgnoqFo$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2411.11829v1 Announce Type: cross Abstract: Though large language models (LLMs) have demonstrated exceptional performance across numerous problems, their application to predictive tasks in relational databases remains largely unexplored. In this work, we address the notion that LLMs cannot yield satisfactory results on relational databases due to their interconnected tables, complex relationships, and heterogeneous data types. Using the recently introduced RelBench benchmark, we demonstrate that even a straightforward application of LLMs achieves competitive performance on these tasks. These findings establish LLMs as a promising new baseline for ML on relational databases and encourage further research in this direction.|] 

TITLE[|Bullion: A Column Store for Machine Learning <https://urldefense.com/v3/__https://arxiv.org/abs/2404.08901__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitYttx7DA$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2404.08901v2 Announce Type: replace Abstract: The past two decades have witnessed significant success in applying columnar storage to data warehousing and analytics. However, the rapid growth of machine learning poses new challenges. This paper presents Bullion, a columnar storage system tailored for machine learning workloads. Bullion addresses the complexities of data compliance, optimizes the encoding of long sequence sparse features, efficiently manages wide-table projections, introduces feature quantization in storage, enables quality-aware sequential reads for multimodal training data, and provides a comprehensive cascading encoding framework that unifies diverse encoding schemes through modular, composable interfaces. By aligning with the evolving requirements of ML applications, Bullion facilitates the application of columnar storage and processing to modern application scenarios such as those within advertising, recommendation systems, and Generative AI. Preliminary experimental results and theoretical analysis demonstrate Bullion's improved ability to deliver strong performance in the face of the unique demands of machine learning workloads compared to existing columnar storage solutions. Bullion significantly reduces I/O costs for deletion compliance, achieves substantial storage savings with its optimized encoding scheme for sparse features, and improves metadata parsing speed for wide-table projections. These advancements enable Bullion to become an important component in the future of machine learning infrastructure, enabling organizations to efficiently manage and process the massive volumes of data required for training and inference in modern AI applications.|] 

TITLE[|UQE: A Query Engine for Unstructured Databases <https://urldefense.com/v3/__https://arxiv.org/abs/2407.09522__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitcmj0mXU$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2407.09522v2 Announce Type: replace Abstract: Analytics on structured data is a mature field with many successful methods. However, most real world data exists in unstructured form, such as images and conversations. We investigate the potential of Large Language Models (LLMs) to enable unstructured data analytics. In particular, we propose a new Universal Query Engine (UQE) that directly interrogates and draws insights from unstructured data collections. This engine accepts queries in a Universal Query Language (UQL), a dialect of SQL that provides full natural language flexibility in specifying conditions and operators. The new engine leverages the ability of LLMs to conduct analysis of unstructured data, while also allowing us to exploit advances in sampling and optimization techniques to achieve efficient and accurate query execution. In addition, we borrow techniques from classical compiler theory to better orchestrate the workflow between sampling methods and foundation model calls. We demonstrate the efficiency of UQE on data analytics across different modalities, including images, dialogs and reviews, across a range of useful query types, including conditional aggregation, semantic retrieval and abstraction aggregation.|] 

TITLE[|Semantic Operators: A Declarative Model for Rich, AI-based Analytics Over Text Data <https://urldefense.com/v3/__https://arxiv.org/abs/2407.11418__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitdZ38Uhc$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2407.11418v2 Announce Type: replace Abstract: The semantic capabilities of language models (LMs) have the potential to enable rich analytics and reasoning over vast knowledge corpora. Unfortunately, existing systems lack high-level abstractions to perform bulk semantic queries across large corpora. We introduce semantic operators, a declarative programming interface that extends the relational model with composable AI-based operations for bulk semantic queries (e.g., filtering, sorting, joining or aggregating records using natural language criteria). Each operator can be implemented and optimized in multiple ways, opening a rich space for execution plans similar to relational operators. We implement our operators in LOTUS, an open source query engine with a DataFrame API. Furthermore, we develop several novel optimizations that take advantage of the declarative nature of semantic operators to accelerate semantic filtering, clustering and join operators by up to $400\times$ while offering statistical accuracy guarantees. We demonstrate LOTUS' effectiveness on real AI applications including fact-checking, extreme multi-label classification, and search. We show that the semantic operator model is expressive, capturing state-of-the-art AI pipelines in a few operator calls, and making it easy to express new pipelines that achieve up to $180\%$ higher quality. Overall, LOTUS queries match or exceed the accuracy of state-of-the-art AI pipelines for each task while running up to 28$\times$ faster. LOTUS is publicly available at https://github.com/stanford-futuredata/lotus <https://urldefense.com/v3/__https://github.com/stanford-futuredata/lotus__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitrChIAY4$> .|] 

TITLE[|Hybrid Querying Over Relational Databases and Large Language Models <https://urldefense.com/v3/__https://arxiv.org/abs/2408.00884__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitb2SieB0$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2408.00884v2 Announce Type: replace Abstract: Database queries traditionally operate under the closed-world assumption, providing no answers to questions that require information beyond the data stored in the database. Hybrid querying using SQL offers an alternative by integrating relational databases with large language models (LLMs) to answer beyond-database questions. In this paper, we present the first cross-domain benchmark, SWAN, containing 120 beyond-database questions over four real-world databases. To leverage state-of-the-art language models in addressing these complex questions in SWAN, we present two solutions: one based on schema expansion and the other based on user defined functions. We also discuss optimization opportunities and potential future directions. Our evaluation demonstrates that using GPT-4 Turbo with few-shot prompts, one can achieves up to 40.0\% in execution accuracy and 48.2\% in data factuality. These results highlights both the potential and challenges for hybrid querying. We believe that our work will inspire further research in creating more efficient and accurate data systems that seamlessly integrate relational databases and large language models to address beyond-database questions.|] 

TITLE[|Flow with FlorDB: Incremental Context Maintenance for the Machine Learning Lifecycle <https://urldefense.com/v3/__https://arxiv.org/abs/2408.02498__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitQEkGTZ8$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2408.02498v2 Announce Type: replace Abstract: In this paper we present techniques to incrementally harvest and query arbitrary metadata from machine learning pipelines, without disrupting agile practices. We center our approach on the developer-favored technique for generating metadata -- log statements -- leveraging the fact that logging creates context. We show how hindsight logging allows such statements to be added and executed post-hoc, without requiring developer foresight. Relational views of incomplete metadata can be queried to dynamically materialize new metadata in bulk and on demand across multiple versions of workflows. This is done in a ""metadata later"" style, off the critical path of agile development. We realize these ideas in a system called FlorDB and demonstrate how the data context framework covers a range of both ad-hoc metadata as well as special cases treated today by bespoke feature stores and model repositories. Through a usage scenario -- including both ML and human feedback -- we illustrate how the component techniques come together to resolve classic software engineering trade-offs between agility and discipline.|] 

TITLE[|Realizing a Collaborative RDF Benchmark Suite in Practice <https://urldefense.com/v3/__https://arxiv.org/abs/2410.12965__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruitifDJAPY$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2410.12965v2 Announce Type: replace Abstract: Collaborative mechanisms allow benchmarks to be updated continuously and adjust to the changing requirements and new use cases. This paradigm is employed for example in the field of machine learning, but up until now there were no examples of truly open and collaborative benchmarks for RDF systems. In this demo paper we present the collaboration functionalities of RiverBench, an open, multi-task RDF benchmark suite. Owing to its fully open and community-driven design, RiverBench allows any researcher or practitioner to submit a new dataset or benchmark task, report performed benchmark runs, and edit any resource in the suite. RiverBench's collaboration system is itself based on RDF and Linked Data mechanisms, and every resource in the suite has machine-readable RDF metadata. The showcased functionalities together make up a first-of-a-kind fully open and collaborative RDF benchmark suite. These features are meant to encourage other researchers to contribute to RiverBench, and make it a long-term project sustained by the community.|] 

TITLE[|LSMGraph: A High-Performance Dynamic Graph Storage System with Multi-Level CSR <https://urldefense.com/v3/__https://arxiv.org/abs/2411.06392__;!!Hwoz3Kc!V9qOnEMj3Pt9w_-oXiHCStExbHuqgn65V79NT_ct0hXs96S5nZiKacv-EJ5uXKWcq92guQ1HX2k634e9-muGQTBVruit273WI7o$> |]

POSTED AT[| 5:00 AM GMT|]
SOURCE[|Cornwell|]
SUMMARY[|arXiv:2411.06392v2 Announce Type: replace Abstract: The growing volume of graph data may exhaust the main memory. It is crucial to design a disk-based graph storage system to ingest updates and analyze graphs efficiently. However, existing dynamic graph storage systems suffer from read or write amplification and face the challenge of optimizing both read and write performance simultaneously. To address this challenge, we propose LSMGraph, a novel dynamic graph storage system that combines the write-friendly LSM-tree and the read-friendly CSR. It leverages the multi-level structure of LSM-trees to optimize write performance while utilizing the compact CSR structures embedded in the LSM-trees to boost read performance. LSMGraph uses a new memory structure, MemGraph, to efficiently cache graph updates and uses a multi-level index to speed up reads within the multi-level structure. Furthermore, LSMGraph incorporates a vertex-grained version control mechanism to mitigate the impact of LSM-tree compaction on read performance and ensure the correctness of concurrent read and write operations. Our evaluation shows that LSMGraph significantly outperforms state-of-the-art (graph) storage systems on both graph update and graph analytical workloads.|] 

","Microsoft Power Automate","PowerAutomateNoReply@microsoft.com","SMTP","BIRAUD Maxime-I (CAR-HK)","/o=ExchangeLabs/ou=Exchange Administrative Group (FYDIBOHF23SPDLT)/cn=Recipients/cn=217576b3f1314a44a3cd951c50113b70-35df04db-66","EX"
"[EXT] [RSS] Feed from MIT AI","CAUTION: This email originated from outside of our organization. Unless you recognize the sender and know that the content is safe, do not click on links or open attachments. For questions please contact Group CSIRT	 


TITLE[|A model of virtuosity <https://urldefense.com/v3/__https://news.mit.edu/2024/model-virtuosity-jordan-rudess-jam-bot-1119__;!!Hwoz3Kc!UMas41tNjFMZz3U63KUKm8Y3zD1cE7aha4wbxCpgKv7WsLEkP9tKBHlSkZgKyvaI4FyOFtop0oCj3SUMGitUWualWUzZ5UgAO9M$> |]

POSTED AT[| 8:30 PM GMT|]
SOURCE[|MIT AI|]
SUMMARY[|Acclaimed keyboardist Jordan Rudess’s collaboration with the MIT Media Lab culminates in live improvisation between an AI “jam_bot” and the artist.|] 

TITLE[|Can robots learn from machine dreams? <https://urldefense.com/v3/__https://news.mit.edu/2024/can-robots-learn-machine-dreams-1119__;!!Hwoz3Kc!UMas41tNjFMZz3U63KUKm8Y3zD1cE7aha4wbxCpgKv7WsLEkP9tKBHlSkZgKyvaI4FyOFtop0oCj3SUMGitUWualWUzZL8M4Nf8$> |]

POSTED AT[| 7:50 PM GMT|]
SOURCE[|MIT AI|]
SUMMARY[|MIT CSAIL researchers used AI-generated images to train a robot dog in parkour, without real-world data. Their LucidSim system demonstrates generative AI's potential for creating robotics training data.|] 

","Microsoft Power Automate","PowerAutomateNoReply@microsoft.com","SMTP","BIRAUD Maxime-I (CAR-HK)","/o=ExchangeLabs/ou=Exchange Administrative Group (FYDIBOHF23SPDLT)/cn=Recipients/cn=217576b3f1314a44a3cd951c50113b70-35df04db-66","EX"
"[EXT] [RSS] Feed from Meta RSS feed","CAUTION: This email originated from outside of our organization. Unless you recognize the sender and know that the content is safe, do not click on links or open attachments. For questions please contact Group CSIRT	 


TITLE[|Reshape Your Instagram With a Recommendations Reset <https://urldefense.com/v3/__https://about.fb.com/news/2024/11/introducing-recommendations-reset-instagram/__;!!Hwoz3Kc!XPkztfxgM6qufBOe_YZR5N2LvVlzP0AWvLCXqaNI_GpWmFld9E_gMeH2DvUxrYoz__BFY76WwgwG5vcerl1VLaWapi1UavbllfM$> |]

POSTED AT[| 12:00 PM GMT|]
SOURCE[|Meta RSS feed|]
SUMMARY[| 
 <https://about.fb.com/wp-content/uploads/2024/11/Recommendations-Reset_Thumbnail.jpg?fit=890%2C501> 

We’re testing a way for people to reset the content recommendations they see in Explore, Reels and Feed when they want a fresh start. 

The post Reshape Your Instagram With a Recommendations Reset <https://urldefense.com/v3/__https://about.fb.com/news/2024/11/introducing-recommendations-reset-instagram/__;!!Hwoz3Kc!XPkztfxgM6qufBOe_YZR5N2LvVlzP0AWvLCXqaNI_GpWmFld9E_gMeH2DvUxrYoz__BFY76WwgwG5vcerl1VLaWapi1UavbllfM$>  appeared first on Meta <https://urldefense.com/v3/__https://about.fb.com__;!!Hwoz3Kc!XPkztfxgM6qufBOe_YZR5N2LvVlzP0AWvLCXqaNI_GpWmFld9E_gMeH2DvUxrYoz__BFY76WwgwG5vcerl1VLaWapi1UG2i35LE$> .

|] 

TITLE[|Meta’s Llama Impact Hackathon: Pioneering AI Solutions for Public Good <https://urldefense.com/v3/__https://about.fb.com/news/2024/11/metas-llama-impact-hackathon-pioneering-ai-solutions-for-public-good/__;!!Hwoz3Kc!XPkztfxgM6qufBOe_YZR5N2LvVlzP0AWvLCXqaNI_GpWmFld9E_gMeH2DvUxrYoz__BFY76WwgwG5vcerl1VLaWapi1UOrdgp2M$> |]

POSTED AT[| 11:43 AM GMT|]
SOURCE[|Meta RSS feed|]
SUMMARY[| 
 <https://about.fb.com/wp-content/uploads/2024/11/Nick-Clegg-AI-Minister-Feryal-Clark-and-Winning-Team-Guardian.jpg?fit=960%2C701> 

Meta yesterday concluded its groundbreaking Llama Impact Hackathon in London, marking a significant milestone in AI innovation aimed at transforming public services. The event, held in collaboration with Cerebral Valley brought together over 200 developers across 56 teams, all leveraging Meta’s open source Llama 3.2 model to address critical challenges in healthcare, clean energy, and social mobility. Revolutionising NHS Frontline Services The winning team, Guardian, developed a concept of an AI-powered triage assistant which could reduce waiting times and better allocate resources in A&E departments. This innovative solution, built on Llama 3.2, enhances patient care through intelligent patient intake and real-time risk assessments. Guardian’s tool, Atlas, acts as a clinical AI agent, providing crucial support to frontline medical staff and facilitating communication in multiple languages to improve patient evaluations. Celebrating Innovation and Collaboration The hackathon showcased the potential of open source AI to drive positive social impact. The top three teams shared a prize fund of $50,000 and will receive six weeks of technical mentorship to further develop their projects. Participation in this hackathon also enables these teams to apply for both regional grants of up to $100K and global grants of up to $500K through the Llama 3.1 Impact Grants which close on 1st December 2024. Empowering Developers and Researchers “It was inspiring to be at Meta and discuss how open source AI can be harnessed for public benefit. Whether accelerating cancer diagnoses, boosting productivity, or developing new tools to combat climate change, this technology holds immense potential. That’s why we’re placing AI at the forefront to not only improve public services and stimulate economic growth but also deliver a brighter future for communities across the country,” – UK Minister for AI Feryal Clark. “The UK has the developer talent, research base, and creativity to lead in deploying AI. With access to open source AI models like Llama, developers and researchers can craft tools and systems tailored to Britain’s challenges, from enhancing public service delivery to boosting workplace productivity and aiding scientific breakthroughs. We eagerly anticipate these projects coming to life and look forward to working with our winners as well as the UK Government to develop them further.” – Nick Clegg, President of Global Affairs at Meta. “The talent at this London Llama Hackathon was some of the best we’ve ever seen. More than 200 developers come out to build projects for the public good and demonstrate how open source AI can create positive social impact.” – Ivan Porollo Founder, Cerebral Valley. Meet the Finalists We would like to extend our congratulations to all the finalists who participated in the UK Llama Impact Hackathon. Their innovative projects demonstrate the vast potential of AI to drive positive change in the UK’s public services. Here were the finalists: First place – Guardian: An AI-powered triage assistant to support frontline NHS staff. Built on Llama 3.2, Guardian transforms A&E departments through intelligent patient intake, real-time risk assessment, and Atlas – a breakthrough clinical AI agent which provides a second pair of eyes to doctors and nurses. It will also support patients across multiple languages helping them communicate their symptoms better.  Second Place – Gripmind: Is a solution which makes robotics in assisted living more useful, scalable and affordable. An open source project combining the Llama 3.2 Vision model, which processes signals from the brain, your voice or via images to control a robotic arm. It’s envisaged this solution could help support people with mobility issues. Third place – Pharmallama: An on-device app which allows patients to engage with their pharmacist to discuss potential side effects they may be experiencing; understand what medication they need to be on and centralises the patient records to spot potential conflicting medications. This will be particularly beneficial for those with mobility issues or who are unable to access a more local pharmacy.   ClimaticAI: Heat the person, not the home, and save up to a third on energy bills. Their AI-powered concept works with smart devices, infrared-controlled appliances, and IoT sensors to optimise energy use based on presence, cost, and savings goals. Affordable, open source, and easy to use—comfort and efficiency, simplified. Team WinAmp: An intelligent companion app for sustainable eating which makes the healthy choice the easy choice by comparing supermarket offers on healthy food. It uses Llama to create highly personalised meal plans and habit-forming coaching, which is accessible at scale. The GoodPath: A platform which creates a roadmap into a socially impactful career – including culturally-relevant explanations, visual diagrams and translations into underserved regional dialects. It has a tutor function which can guide you on everything from how to give strong interview answers to flash cards for exam preparation.  A Commitment to Open Source We believe an open approach best ensures AI delivers broad benefits to society. This is why we make Llama free and openly available for anyone to access and download. Since 2023, there have been more than 400 million downloads of all Llama versions, demonstrating how Llama has been a bedrock for AI innovation globally. Since the release of Llama 2 in July 2023, Meta has issued over $2 million in Llama Impact Grants and Awards, fostering innovation and collaboration across various sectors. Our partners Our partners for this event included Cerebral Valley, Groq, Nebius, and Neon, who provided inference, compute, and data retrieval support for the participants over the weekend.  Cerebral Valley is the biggest AI community in the world with 40,000+ of the best developers in the industry. Groq provided 1,000+ tok/s Llama model inference for hackers. Nebius provisioned each team an H100 VM for compute and model fine-tuning. Neon provided a simple serverless database environment.  Looking Ahead The Llama Impact Hackathon is just one of many initiatives under Meta’s Llama Impact program, which includes accelerator programs, training, and workshops. These efforts aim to harness the power of open source AI to solve important local and global challenges, ensuring a brighter future for communities worldwide.

The post Meta’s Llama Impact Hackathon: Pioneering AI Solutions for Public Good <https://urldefense.com/v3/__https://about.fb.com/news/2024/11/metas-llama-impact-hackathon-pioneering-ai-solutions-for-public-good/__;!!Hwoz3Kc!XPkztfxgM6qufBOe_YZR5N2LvVlzP0AWvLCXqaNI_GpWmFld9E_gMeH2DvUxrYoz__BFY76WwgwG5vcerl1VLaWapi1UOrdgp2M$>  appeared first on Meta <https://urldefense.com/v3/__https://about.fb.com__;!!Hwoz3Kc!XPkztfxgM6qufBOe_YZR5N2LvVlzP0AWvLCXqaNI_GpWmFld9E_gMeH2DvUxrYoz__BFY76WwgwG5vcerl1VLaWapi1UG2i35LE$> .

|] 

","Microsoft Power Automate","PowerAutomateNoReply@microsoft.com","SMTP","BIRAUD Maxime-I (CAR-HK)","/o=ExchangeLabs/ou=Exchange Administrative Group (FYDIBOHF23SPDLT)/cn=Recipients/cn=217576b3f1314a44a3cd951c50113b70-35df04db-66","EX"
"[EXT] [RSS] Feed from Bloomberg","CAUTION: This email originated from outside of our organization. Unless you recognize the sender and know that the content is safe, do not click on links or open attachments. For questions please contact Group CSIRT	 


TITLE[|China Mobile Discusses Potential Deal for Internet Firm HKBN <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-20/china-mobile-discusses-potential-deal-for-internet-provider-hkbn__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8Mf55ToEz8$> |]

POSTED AT[| 12:22 AM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|China Mobile, the world’s largest wireless carrier by subscribers, is in talks on a potential acquisition of Hong Kong broadband provider HKBN Ltd. as it looks to expand its footprint in the city.|] 

TITLE[|Sony Said to Weigh Deal for Japanese Content House Kadokawa <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-19/sony-in-talks-to-buy-japan-anime-firm-kadokawa-reuters-says__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8Mf86PfsOs$> |]

POSTED AT[| 6:01 AM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|Sony Group Corp. is exploring a takeover of Japanese publisher Kadokawa Corp., potentially expanding its content portfolio and tightening its grip over the maker of hit role-playing game Elden Ring.|] 

TITLE[|China’s SpaceSail to Challenge Elon Musk’s Starlink in Brazil <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-20/china-s-spacesail-to-challenge-elon-musk-s-starlink-in-brazil__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8MfJLniPLA$> |]

POSTED AT[| 1:00 AM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|Elon Musk’s Chinese rival in the satellite internet business plans to start operations in Brazil in 2026, the head of the Shanghai-based company told Bloomberg News Tuesday.|] 

TITLE[|SpaceX Starship Blasts Off, Splashes Down in Key Test <https://urldefense.com/v3/__https://www.bloomberg.com/news/videos/2024-11-19/spacex-starship-blasts-off-splashes-down-in-key-test-video__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8MfaostnV4$> |]

POSTED AT[| 11:50 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|SpaceX’s Starship rocket launched from South Texas in a key test, with President-elect Donald Trump in attendance.|] 

TITLE[|Sequoia, General Catalyst, GV Back AI Startup for Salespeople <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-19/sequoia-gv-back-startup-building-ai-agents-for-salespeople__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8MfhpJBi04$> |]

POSTED AT[| 2:00 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|Rox, a startup working on developing artificial intelligence-powered agents for salespeople, has launched with $50 million in funding from investors including Sequoia Capital and General Catalyst, the company plans to announce Tuesday.|] 

TITLE[|T-Mobile Refutes Analyst Report That It Plans to Drop Nokia <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-19/nokia-drops-after-analyst-predicts-t-mobile-will-swap-suppliers__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8MfBunRo-k$> |]

POSTED AT[| 5:30 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|T-Mobile US Inc. said it doesn’t plan to stop purchasing network gear from Nokia Oyj, refuting an analyst’s prediction that telecom giant would switch suppliers.|] 

TITLE[|T-Mobile Caught Hackers Early, Averting Data Leak <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-19/t-mobile-said-to-have-caught-hackers-early-averting-data-leak__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8MfV0_e38o$> |]

POSTED AT[| 10:05 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|T-Mobile US Inc. was able to contain a recent network breach before it reached customers’ phones, according to people familiar with the matter.|] 

TITLE[|Slot Machine Operator International Game Reports Hacker Incident <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-19/slot-machine-operator-international-game-reports-hacker-incident__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8Mf1VC9aD0$> |]

POSTED AT[| 10:29 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|International Game Technology Plc, operator of popular slot machines in casinos, said an unauthorized third party gained access to certain of its systems.|] 

TITLE[|Bling Capital Raises $270 Million to Invest in Nascent Startups <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-19/bling-capital-raises-270-million-to-invest-in-nascent-startups__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8MfQfCw94w$> |]

POSTED AT[| 10:00 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|Bling Capital, a venture firm targeting the earliest of startups, has raised $270 million at a difficult time for most of the venture capital industry.|] 

TITLE[|Motorola Solutions CEO Sees Trump as Favorable to Business <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-19/motorola-solutions-ceo-sees-trump-as-favorable-to-business__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8MfY4obFYw$> |]

POSTED AT[| 9:56 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|Motorola Solutions Inc. Chief Executive Officer Greg Brown said the incoming administration of President-elect Donald Trump will be favorable to a business that’s already doing very well.|] 

TITLE[|Alibaba Sells First Dollar Bonds Since 2021 to Fund Buybacks <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-19/china-s-alibaba-markets-its-first-dollar-bonds-since-2021__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8Mf_KKjWjg$> |]

POSTED AT[| 5:01 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|Alibaba Group Holding Ltd. sold its first public dollar bonds in nearly four years, part of a dual-currency transaction by the Chinese internet heavyweight to repay offshore debt and repurchase equity.|] 

TITLE[|Westpac NZ CEO Urges Fintech Accreditation to Speed Open Banking <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-19/westpac-nz-ceo-urges-fintech-accreditation-to-speed-open-banking__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8Mf4NpGYIQ$> |]

POSTED AT[| 9:35 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|New Zealand should consider an accreditation regime for emerging fintechs if it wants open banking to get support from consumers, according to Westpac New Zealand Chief Executive Office Catherine McGrath.|] 

TITLE[|The DOJ Goes After Google Chrome | Bloomberg Technology <https://urldefense.com/v3/__https://www.bloomberg.com/news/videos/2024-11-19/bloomberg-technology-11-19-2024-video__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8MfP_zvrww$> |]

POSTED AT[| 9:28 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|Bloomberg's Caroline Hyde discusses the DOJ's push on Google to sell off its Chrome browser over concerns of a ""search"" monopoly. And, Roblox aims to enhance its child safety policies with the aid of AI. Plus, SpaceX hopes for a ""catch"" repeat as it readies to launch its Starship rocket with President-elect Trump in attendance. (Source: Bloomberg)|] 

TITLE[|Qualcomm Expects to Make $22 Billion by 2029 From Expansion Bid <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-19/qualcomm-expects-to-make-22-billion-by-2029-from-expansion-bid__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8MfjuO68Bg$> |]

POSTED AT[| 9:25 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|Qualcomm Inc., the world’s biggest seller of smartphone processors, is expecting its push into new markets to generate an additional $22 billion in annual revenue by fiscal 2029.|] 

TITLE[|US Electric Vehicle Demand Seen Plunging 27% Without Tax Credit <https://urldefense.com/v3/__https://www.bloomberg.com/news/articles/2024-11-19/us-electric-vehicle-demand-seen-plunging-27-without-tax-credit__;!!Hwoz3Kc!Rv4AzBcWG2Q4_qpxnIgwPZeXT7joVy6T2s3Oopm_G0Q2ojKDEuC64u9gBnftGF9oRUns8ukk42AwBngTRMq7aTUNM8MfLKhX0eQ$> |]

POSTED AT[| 8:42 PM GMT|]
SOURCE[|Bloomberg|]
SUMMARY[|Eliminating the US electric vehicle tax credit would dent future EV demand — perhaps by more than a fourth — while providing a trivial boost to gasoline consumption, economists estimate.|] 

","Microsoft Power Automate","PowerAutomateNoReply@microsoft.com","SMTP","BIRAUD Maxime-I (CAR-HK)","/o=ExchangeLabs/ou=Exchange Administrative Group (FYDIBOHF23SPDLT)/cn=Recipients/cn=217576b3f1314a44a3cd951c50113b70-35df04db-66","EX"
"[EXT] [RSS] Feed from Amazon","CAUTION: This email originated from outside of our organization. Unless you recognize the sender and know that the content is safe, do not click on links or open attachments. For questions please contact Group CSIRT	 


TITLE[|Racing into the future: How AWS DeepRacer fueled my AI and ML journey <https://urldefense.com/v3/__https://aws.amazon.com/blogs/machine-learning/racing-into-the-future-how-aws-deepracer-fueled-my-ai-and-ml-journey/__;!!Hwoz3Kc!R0hhLLTOfpJth3pULtqMzz8c9Oc9jNbLjkaIYv6GNa0W0TNF7xh2mTtSBOTPxt4bYSki50YsrB4RZn5Z7x2gIPCO5LVcwP9DVdw$> |]

POSTED AT[| 8:52 PM GMT|]
SOURCE[|Amazon|]
SUMMARY[|In 2018, I sat in the audience at AWS re:Invent as Andy Jassy announced AWS DeepRacer—a fully autonomous 1/18th scale race car driven by reinforcement learning. At the time, I knew little about AI or machine learning (ML). As an engineer transitioning from legacy networks to cloud technologies, I had never considered myself a developer. […]|] 

TITLE[|Your guide to generative AI and ML at AWS re:Invent 2024 <https://urldefense.com/v3/__https://aws.amazon.com/blogs/machine-learning/your-guide-to-generative-ai-and-ml-at-aws-reinvent-2024/__;!!Hwoz3Kc!R0hhLLTOfpJth3pULtqMzz8c9Oc9jNbLjkaIYv6GNa0W0TNF7xh2mTtSBOTPxt4bYSki50YsrB4RZn5Z7x2gIPCO5LVcOr_eXww$> |]

POSTED AT[| 8:25 PM GMT|]
SOURCE[|Amazon|]
SUMMARY[|In this attendee guide, we’re highlighting a few of our favorite sessions to give you a glimpse into what’s in store. To help you plan your agenda for this year’s re:Invent, here are some highlights of the generative AI and ML sessions. Visit the session catalog to learn about all our generative AI and ML sessions.|] 

TITLE[|Customize small language models on AWS with automotive terminology <https://urldefense.com/v3/__https://aws.amazon.com/blogs/machine-learning/customize-small-language-models-on-aws-with-automotive-terminology/__;!!Hwoz3Kc!R0hhLLTOfpJth3pULtqMzz8c9Oc9jNbLjkaIYv6GNa0W0TNF7xh2mTtSBOTPxt4bYSki50YsrB4RZn5Z7x2gIPCO5LVc64Et6EM$> |]

POSTED AT[| 6:13 PM GMT|]
SOURCE[|Amazon|]
SUMMARY[|In this post, we guide you through the phases of customizing SLMs on AWS, with a specific focus on automotive terminology for diagnostics as a Q&A task. We begin with the data analysis phase and progress through the end-to-end process, covering fine-tuning, deployment, and evaluation. We compare a customized SLM with a general purpose LLM, using various metrics to assess vocabulary richness and overall accuracy.|] 

TITLE[|Automate emails for task management using Amazon Bedrock Agents, Amazon Bedrock Knowledge Bases, and Amazon Bedrock Guardrails <https://urldefense.com/v3/__https://aws.amazon.com/blogs/machine-learning/automate-emails-for-task-management-using-amazon-bedrock-agents-amazon-bedrock-knowledge-bases-and-amazon-bedrock-guardrails/__;!!Hwoz3Kc!R0hhLLTOfpJth3pULtqMzz8c9Oc9jNbLjkaIYv6GNa0W0TNF7xh2mTtSBOTPxt4bYSki50YsrB4RZn5Z7x2gIPCO5LVc4Kl_E-k$> |]

POSTED AT[| 6:05 PM GMT|]
SOURCE[|Amazon|]
SUMMARY[|In this post, we demonstrate how to create an automated email response solution using Amazon Bedrock and its features, including Amazon Bedrock Agents, Amazon Bedrock Knowledge Bases, and Amazon Bedrock Guardrails.|] 

TITLE[|Automate building guardrails for Amazon Bedrock using test-driven development <https://urldefense.com/v3/__https://aws.amazon.com/blogs/machine-learning/automate-building-guardrails-for-amazon-bedrock-using-test-driven-development/__;!!Hwoz3Kc!R0hhLLTOfpJth3pULtqMzz8c9Oc9jNbLjkaIYv6GNa0W0TNF7xh2mTtSBOTPxt4bYSki50YsrB4RZn5Z7x2gIPCO5LVc8p7XdEE$> |]

POSTED AT[| 5:57 PM GMT|]
SOURCE[|Amazon|]
SUMMARY[|Amazon Bedrock Guardrails helps implement safeguards for generative AI applications based on specific use cases and responsible AI policies. Amazon Bedrock Guardrails assists in controlling the interaction between users and foundation models (FMs) by detecting and filtering out undesirable and potentially harmful content, while maintaining safety and privacy. In this post, we explore a solution that automates building guardrails using a test-driven development approach.|] 

","Microsoft Power Automate","PowerAutomateNoReply@microsoft.com","SMTP","BIRAUD Maxime-I (CAR-HK)","/o=ExchangeLabs/ou=Exchange Administrative Group (FYDIBOHF23SPDLT)/cn=Recipients/cn=217576b3f1314a44a3cd951c50113b70-35df04db-66","EX"
"[EXT] [RSS] Feed from artificiallawyer","CAUTION: This email originated from outside of our organization. Unless you recognize the sender and know that the content is safe, do not click on links or open attachments. For questions please contact Group CSIRT	 


TITLE[|LexisNexis JV Partner Knowable Launches GenAI Doc Q&A <https://urldefense.com/v3/__https://www.artificiallawyer.com/2024/11/19/lexisnexis-jv-partner-knowable-launches-genai-doc-qa/__;!!Hwoz3Kc!XAqYwrRuzQptEb8tvr95QBD1yErF6IANOhR30VC3RFvCZEcDsFiwR5-PyqYo8HRc1jt9G-vBHWXXR9RNEYcg8ku5ShGtOl87aO4$> |]

POSTED AT[| 3:00 PM GMT|]
SOURCE[|artificiallawyer|]
SUMMARY[|Knowable, which has been in a deep joint-venture with LexisNexis since 2019 after spinning out of Axiom, is launching a genAI contract Q&A capability to ... <https://urldefense.com/v3/__https://www.artificiallawyer.com/2024/11/19/lexisnexis-jv-partner-knowable-launches-genai-doc-qa/__;!!Hwoz3Kc!XAqYwrRuzQptEb8tvr95QBD1yErF6IANOhR30VC3RFvCZEcDsFiwR5-PyqYo8HRc1jt9G-vBHWXXR9RNEYcg8ku5ShGtOl87aO4$> |] 

TITLE[|Canada Prof Blasts Lexis+ AI, LexisNexis Fires Back <https://urldefense.com/v3/__https://www.artificiallawyer.com/2024/11/19/canada-prof-blasts-lexis-ai-lexisnexis-fires-back/__;!!Hwoz3Kc!XAqYwrRuzQptEb8tvr95QBD1yErF6IANOhR30VC3RFvCZEcDsFiwR5-PyqYo8HRc1jt9G-vBHWXXR9RNEYcg8ku5ShGtabt4PEY$> |]

POSTED AT[| 7:54 AM GMT|]
SOURCE[|artificiallawyer|]
SUMMARY[|Here we go again. An academic blasts a legal AI tool for not working as expected and the legal tech company moves to defend itself. ... <https://urldefense.com/v3/__https://www.artificiallawyer.com/2024/11/19/canada-prof-blasts-lexis-ai-lexisnexis-fires-back/__;!!Hwoz3Kc!XAqYwrRuzQptEb8tvr95QBD1yErF6IANOhR30VC3RFvCZEcDsFiwR5-PyqYo8HRc1jt9G-vBHWXXR9RNEYcg8ku5ShGtabt4PEY$> |] 

","Microsoft Power Automate","PowerAutomateNoReply@microsoft.com","SMTP","BIRAUD Maxime-I (CAR-HK)","/o=ExchangeLabs/ou=Exchange Administrative Group (FYDIBOHF23SPDLT)/cn=Recipients/cn=217576b3f1314a44a3cd951c50113b70-35df04db-66","EX"
"[EXT] [RSS] Feed from Microsoft","CAUTION: This email originated from outside of our organization. Unless you recognize the sender and know that the content is safe, do not click on links or open attachments. For questions please contact Group CSIRT	 


TITLE[|Ideas: The journey to DNA data storage <https://urldefense.com/v3/__https://www.microsoft.com/en-us/research/podcast/ideas-the-journey-to-dna-data-storage/__;!!Hwoz3Kc!UydPp2hJ3nje1PpLNFAFZE6rTyHKiH9dR0Vj1JYZ_43qwiAQLv30OygCw8n2T3NTctA7k94w1bhabRhR5xkfuel4ZKcPgcr2bpg$> |]

POSTED AT[| 2:00 PM GMT|]
SOURCE[|Microsoft|]
SUMMARY[| 

Research manager Karin Strauss and members of the DNA Data Storage Project reflect on the path to developing a synthetic DNA–based system for archival data storage, including the recent open-source release of its most powerful algorithm for DNA error correction.

The post Ideas: The journey to DNA data storage <https://urldefense.com/v3/__https://www.microsoft.com/en-us/research/podcast/ideas-the-journey-to-dna-data-storage/__;!!Hwoz3Kc!UydPp2hJ3nje1PpLNFAFZE6rTyHKiH9dR0Vj1JYZ_43qwiAQLv30OygCw8n2T3NTctA7k94w1bhabRhR5xkfuel4ZKcPgcr2bpg$>  appeared first on Microsoft Research <https://urldefense.com/v3/__https://www.microsoft.com/en-us/research__;!!Hwoz3Kc!UydPp2hJ3nje1PpLNFAFZE6rTyHKiH9dR0Vj1JYZ_43qwiAQLv30OygCw8n2T3NTctA7k94w1bhabRhR5xkfuel4ZKcPrc1KTR4$> .

|] 

","Microsoft Power Automate","PowerAutomateNoReply@microsoft.com","SMTP","BIRAUD Maxime-I (CAR-HK)","/o=ExchangeLabs/ou=Exchange Administrative Group (FYDIBOHF23SPDLT)/cn=Recipients/cn=217576b3f1314a44a3cd951c50113b70-35df04db-66","EX"
"[EXT] [RSS] Feed from Reddit","CAUTION: This email originated from outside of our organization. Unless you recognize the sender and know that the content is safe, do not click on links or open attachments. For questions please contact Group CSIRT	 


TITLE[|Large Language Models Enable High-Fidelity Behavioral Simulation of 1,000+ Individuals <https://urldefense.com/v3/__https://www.reddit.com/r/neuralnetworks/comments/1guyuki/large_language_models_enable_highfidelity/__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjn__edzc$> |]

POSTED AT[| 2:49 PM GMT|]
SOURCE[|Reddit|]
SUMMARY[| 

I found this paper interesting for its technical approach to creating behavioral simulations using LLMs. The researchers developed a system that generates digital agents based on interview data from real people, achieving high fidelity in replicating human behavior patterns.

Key technical aspects: - Architecture combines LLM-based agents with structured interview processing - Agents are trained on personal narratives to model decision-making - Validation against General Social Survey responses - Tested on 1,052 individuals across diverse demographic groups

Main results: - 85% accuracy in replicating survey responses compared to human consistency - Maintained performance across different racial and ideological groups - Successfully reproduced experimental outcomes from social psychology studies - Reduced demographic bias compared to traditional simulation approaches

The implications for social science research are significant. This methodology could enable more accurate policy testing and social dynamics research by: - Creating representative populations for simulation studies - Testing interventions across diverse groups - Modeling complex social interactions - Reducing demographic biases in research

Technical limitations to consider: - Current validation limited to survey responses and controlled experiments - Long-term behavioral consistency needs further study - Handling of evolving social contexts remains uncertain - Privacy considerations in creating digital representations

TLDR: New methodology creates digital agents that accurately simulate human behavior using LLMs and interview data, achieving 85% accuracy in replicating survey responses. Shows promise for social science research while reducing demographic biases.

Full summary is here <https://urldefense.com/v3/__https://aimodels.fyi/papers/arxiv/generative-agent-simulations-1000-people__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjfPcKX_M$> . Paper here <https://urldefense.com/v3/__https://arxiv.org/abs/2411.10109__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjnLBzwzE$> .

submitted by /u/Successful-Western27 <https://urldefense.com/v3/__https://www.reddit.com/user/Successful-Western27__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjdPkLroI$> 
[link] <https://urldefense.com/v3/__https://www.reddit.com/r/neuralnetworks/comments/1guyuki/large_language_models_enable_highfidelity/__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjn__edzc$>  [comments] <https://urldefense.com/v3/__https://www.reddit.com/r/neuralnetworks/comments/1guyuki/large_language_models_enable_highfidelity/__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjn__edzc$> |] 

TITLE[|Neural Net Framework in C <https://urldefense.com/v3/__https://www.reddit.com/r/neuralnetworks/comments/1gur7ih/neural_net_framework_in_c/__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjnbEnbPQ$> |]

POSTED AT[| 6:45 AM GMT|]
SOURCE[|Reddit|]
SUMMARY[| 

Hello! This is one of my first posts ever, but I'd like feedback on a Neural Network Framework I've been working on recently. It's fully implemented in C, and any input would be appreciated. This is just a side project I've been working on, and the process has been rewarding so far. 

Files of relevance are, main.c, network.c, forward.c, backward.c, and utils.c

https://github.com/Asu-Ghi/Personal_Projects/tree/main/C_Projects/Neural <https://urldefense.com/v3/__https://github.com/Asu-Ghi/Personal_Projects/tree/main/C_Projects/Neural__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjoNfNpuE$>  

Thanks for your time! 

submitted by /u/AsuGhi <https://urldefense.com/v3/__https://www.reddit.com/user/AsuGhi__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjjo7q4RI$> 
[link] <https://urldefense.com/v3/__https://www.reddit.com/r/neuralnetworks/comments/1gur7ih/neural_net_framework_in_c/__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjnbEnbPQ$>  [comments] <https://urldefense.com/v3/__https://www.reddit.com/r/neuralnetworks/comments/1gur7ih/neural_net_framework_in_c/__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjnbEnbPQ$> |] 

TITLE[|Memoripy: Bringing Memory to AI with Short-Term & Long-Term Storage <https://urldefense.com/v3/__https://www.reddit.com/r/neuralnetworks/comments/1gul9nt/memoripy_bringing_memory_to_ai_with_shortterm/__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjDCByE-4$> |]

POSTED AT[| 1:16 AM GMT|]
SOURCE[|Reddit|]
SUMMARY[| 

Hey r/neuralnetworks!

I’ve been working on Memoripy, a Python library that brings real memory capabilities to AI applications. Whether you’re building conversational AI, virtual assistants, or projects that need consistent, context-aware responses, Memoripy offers structured short-term and long-term memory storage to keep interactions meaningful over time.

Memoripy organizes interactions into short-term and long-term memory, prioritizing recent events while preserving important details for future use. This ensures the AI maintains relevant context without being overwhelmed by unnecessary data.

With semantic clustering, similar memories are grouped together, allowing the AI to retrieve relevant context quickly and efficiently. To mimic how we forget and reinforce information, Memoripy features memory decay and reinforcement, where less useful memories fade while frequently accessed ones stay sharp.

One of the key aspects of Memoripy is its focus on local storage. It’s designed to work seamlessly with locally hosted LLMs, making it a great fit for privacy-conscious developers who want to avoid external API calls. Memoripy also integrates with OpenAI and Ollama.

If this sounds like something you could use, check it out on GitHub <https://urldefense.com/v3/__https://github.com/caspianmoon/memoripy__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjB_-ANa4$> ! It’s open-source, and I’d love to hear how you’d use it or any feedback you might have.

submitted by /u/xazarall <https://urldefense.com/v3/__https://www.reddit.com/user/xazarall__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjFDZgihc$> 
[link] <https://urldefense.com/v3/__https://www.reddit.com/r/neuralnetworks/comments/1gul9nt/memoripy_bringing_memory_to_ai_with_shortterm/__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjDCByE-4$>  [comments] <https://urldefense.com/v3/__https://www.reddit.com/r/neuralnetworks/comments/1gul9nt/memoripy_bringing_memory_to_ai_with_shortterm/__;!!Hwoz3Kc!RkBcYLsEookdUtcjIQBvxeLQxd_0_ivzQ9B9nWhW3X3twOY94Gz2rWxFXEzlYQOIsfgQ30gwCX5sZv9fvOidFf3OFCBjDCByE-4$> |] 

","Microsoft Power Automate","PowerAutomateNoReply@microsoft.com","SMTP","BIRAUD Maxime-I (CAR-HK)","/o=ExchangeLabs/ou=Exchange Administrative Group (FYDIBOHF23SPDLT)/cn=Recipients/cn=217576b3f1314a44a3cd951c50113b70-35df04db-66","EX"
"[EXT] [RSS] Feed from MIT ML","CAUTION: This email originated from outside of our organization. Unless you recognize the sender and know that the content is safe, do not click on links or open attachments. For questions please contact Group CSIRT	 


TITLE[|A model of virtuosity <https://urldefense.com/v3/__https://news.mit.edu/2024/model-virtuosity-jordan-rudess-jam-bot-1119__;!!Hwoz3Kc!X1NIrjM7nDE9myTcsCH1LN06pCwk0xN48m0IYmtQEQjuvU1diNTpyWod7_74EK7Nc6Wud-NMxVFI6PAK3vZiY9UDP2OMnyuEat4$> |]

POSTED AT[| 8:30 PM GMT|]
SOURCE[|MIT ML|]
SUMMARY[|Acclaimed keyboardist Jordan Rudess’s collaboration with the MIT Media Lab culminates in live improvisation between an AI “jam_bot” and the artist.|] 

TITLE[|Can robots learn from machine dreams? <https://urldefense.com/v3/__https://news.mit.edu/2024/can-robots-learn-machine-dreams-1119__;!!Hwoz3Kc!X1NIrjM7nDE9myTcsCH1LN06pCwk0xN48m0IYmtQEQjuvU1diNTpyWod7_74EK7Nc6Wud-NMxVFI6PAK3vZiY9UDP2OMedORh0E$> |]

POSTED AT[| 7:50 PM GMT|]
SOURCE[|MIT ML|]
SUMMARY[|MIT CSAIL researchers used AI-generated images to train a robot dog in parkour, without real-world data. Their LucidSim system demonstrates generative AI's potential for creating robotics training data.|] 

","Microsoft Power Automate","PowerAutomateNoReply@microsoft.com","SMTP","BIRAUD Maxime-I (CAR-HK)","/o=ExchangeLabs/ou=Exchange Administrative Group (FYDIBOHF23SPDLT)/cn=Recipients/cn=217576b3f1314a44a3cd951c50113b70-35df04db-66","EX"
"[EXT] [RSS] Feed from Nvidia","CAUTION: This email originated from outside of our organization. Unless you recognize the sender and know that the content is safe, do not click on links or open attachments. For questions please contact Group CSIRT	 


TITLE[|AI at COP29: Balancing Innovation and Sustainability <https://urldefense.com/v3/__https://blogs.nvidia.com/blog/cop29-energy-efficiency-panel/__;!!Hwoz3Kc!SR_ckWvYZpnJDx5Bu4Gv7Lmr2X1qZMZwHRHX7J54TYuLBUfRcfztIXILduhOQZ5uooKbxVhTg4qRO35QJZjTwm9KPdorPfLKMu4$> |]

POSTED AT[| 7:50 PM GMT|]
SOURCE[|Nvidia|]
SUMMARY[|As COP29 attendees gather in Baku, Azerbaijan, to tackle climate change, the role AI plays in environmental sustainability is front and center. A panel hosted by Deloitte brought together industry leaders to explore ways to reduce AI’s environmental footprint and align its growth with climate goals. Experts from Crusoe Energy Systems, EON, the International Energy Read Article <https://urldefense.com/v3/__https://blogs.nvidia.com/blog/cop29-energy-efficiency-panel/__;!!Hwoz3Kc!SR_ckWvYZpnJDx5Bu4Gv7Lmr2X1qZMZwHRHX7J54TYuLBUfRcfztIXILduhOQZ5uooKbxVhTg4qRO35QJZjTwm9KPdorPfLKMu4$> |] 

TITLE[|How the Department of Energy’s AI Initiatives Are Transforming Science, Industry and Government <https://urldefense.com/v3/__https://blogs.nvidia.com/blog/department-of-energy-ai-podcast/__;!!Hwoz3Kc!SR_ckWvYZpnJDx5Bu4Gv7Lmr2X1qZMZwHRHX7J54TYuLBUfRcfztIXILduhOQZ5uooKbxVhTg4qRO35QJZjTwm9KPdorIUgCZ0c$> |]

POSTED AT[| 5:00 PM GMT|]
SOURCE[|Nvidia|]
SUMMARY[|The U.S. Department of Energy oversees national energy policy and production. As big a job as that is, the DOE also does so much more — enough to have earned the nickname “Department of Everything.” In this episode of the NVIDIA AI Podcast, Helena Fu, director of the DOE’s Office of Critical and Emerging Technologies Read Article <https://urldefense.com/v3/__https://blogs.nvidia.com/blog/department-of-energy-ai-podcast/__;!!Hwoz3Kc!SR_ckWvYZpnJDx5Bu4Gv7Lmr2X1qZMZwHRHX7J54TYuLBUfRcfztIXILduhOQZ5uooKbxVhTg4qRO35QJZjTwm9KPdorIUgCZ0c$> |] 

TITLE[|NVIDIA and Microsoft Showcase Blackwell Preview, Omniverse Industrial AI and RTX AI PCs at Microsoft Ignite <https://urldefense.com/v3/__https://blogs.nvidia.com/blog/microsoft-ignite-blackwell-omniverse-rtx-ai/__;!!Hwoz3Kc!SR_ckWvYZpnJDx5Bu4Gv7Lmr2X1qZMZwHRHX7J54TYuLBUfRcfztIXILduhOQZ5uooKbxVhTg4qRO35QJZjTwm9KPdorlTRFbIM$> |]

POSTED AT[| 1:30 PM GMT|]
SOURCE[|Nvidia|]
SUMMARY[|NVIDIA and Microsoft today unveiled product integrations designed to advance full-stack NVIDIA AI development on Microsoft platforms and applications. At Microsoft Ignite, Microsoft announced the launch of the first cloud private preview of the Azure ND GB200 V6 VM series, based on the NVIDIA Blackwell platform. The Azure ND GB200 v6 will be a new Read Article <https://urldefense.com/v3/__https://blogs.nvidia.com/blog/microsoft-ignite-blackwell-omniverse-rtx-ai/__;!!Hwoz3Kc!SR_ckWvYZpnJDx5Bu4Gv7Lmr2X1qZMZwHRHX7J54TYuLBUfRcfztIXILduhOQZ5uooKbxVhTg4qRO35QJZjTwm9KPdorlTRFbIM$> |] 

TITLE[|Microsoft and NVIDIA Supercharge AI Development on RTX AI PCs <https://urldefense.com/v3/__https://blogs.nvidia.com/blog/ai-decoded-microsoft-ignite-rtx/__;!!Hwoz3Kc!SR_ckWvYZpnJDx5Bu4Gv7Lmr2X1qZMZwHRHX7J54TYuLBUfRcfztIXILduhOQZ5uooKbxVhTg4qRO35QJZjTwm9KPdorIfkBDfw$> |]

POSTED AT[| 1:30 PM GMT|]
SOURCE[|Nvidia|]
SUMMARY[|Generative AI-powered laptops and PCs are unlocking advancements in gaming, content creation, productivity and development. |] 

","Microsoft Power Automate","PowerAutomateNoReply@microsoft.com","SMTP","BIRAUD Maxime-I (CAR-HK)","/o=ExchangeLabs/ou=Exchange Administrative Group (FYDIBOHF23SPDLT)/cn=Recipients/cn=217576b3f1314a44a3cd951c50113b70-35df04db-66","EX"
